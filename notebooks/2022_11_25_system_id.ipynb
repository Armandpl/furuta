{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Check if the model is differentiable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "class QubeDynamics(torch.nn.Module):\n",
    "    \"\"\"Solve equation M qdd + C(q, qd) = tau for qdd.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Gravity\n",
    "        # self.g = Parameter(data=torch.Tensor([9.81]), requires_grad=True)\n",
    "        self.g = torch.tensor([9.81])\n",
    "\n",
    "        # Motor\n",
    "        self.Rm = Parameter(data=torch.Tensor([8.4]), requires_grad=True)\n",
    "\n",
    "        # back-emf constant (V-s/rad)\n",
    "        self.km = Parameter(data=torch.Tensor([0.042]), requires_grad=True)\n",
    "\n",
    "        # Rotary arm\n",
    "        self.Mr = Parameter(data=torch.Tensor([0.095]), requires_grad=True)\n",
    "        self.Lr = Parameter(data=torch.Tensor([0.085]), requires_grad=True)\n",
    "        self.Dr = Parameter(data=torch.Tensor([5e-6]), requires_grad=True)\n",
    "\n",
    "        # Pendulum link\n",
    "        self.Mp = Parameter(data=torch.Tensor([0.024]), requires_grad=True)\n",
    "        self.Lp = Parameter(data=torch.Tensor([0.129]), requires_grad=True)\n",
    "        self.Dp = Parameter(data=torch.Tensor([1e-6]), requires_grad=True)\n",
    "\n",
    "        # Init constants\n",
    "        # self._init_const()\n",
    "\n",
    "    def set_random_params(self):\n",
    "        for p in self.parameters():\n",
    "            p.data = torch.rand_like(p.data)/10 # most params between 0 and 0.1\n",
    "\n",
    "        # except for Rm\n",
    "        self.Rm = Parameter(data=torch.Tensor([5]), requires_grad=True)\n",
    "        \n",
    "        # self._init_const()\n",
    "\n",
    "    def _init_const(self):\n",
    "        # Moments of inertia\n",
    "        Jr = self.Mr * self.Lr ** 2 / 12  # inertia about COM (kg-m^2)\n",
    "        Jp = self.Mp * self.Lp ** 2 / 12  # inertia about COM (kg-m^2)\n",
    "\n",
    "        # Constants for equations of motion\n",
    "        self._c = torch.zeros(5)\n",
    "        self._c[0] = Jr + self.Mp * self.Lr ** 2\n",
    "        self._c[1] = 0.25 * self.Mp * self.Lp ** 2\n",
    "        self._c[2] = 0.5 * self.Mp * self.Lp * self.Lr\n",
    "        self._c[3] = Jp + self._c[1]\n",
    "        self._c[4] = 0.5 * self.Mp * self.Lp * self.g\n",
    "\n",
    "\n",
    "    def forward(self, s, u, dt):\n",
    "        th, al, thd, ald = s\n",
    "        voltage = u[0] * 12\n",
    "\n",
    "        # need to re-init each time we update params\n",
    "        self._init_const()\n",
    "\n",
    "        # Define mass matrix M = [[a, b], [b, c]]\n",
    "        a = self._c[0] + self._c[1] * torch.sin(al) ** 2\n",
    "        b = self._c[2] * torch.cos(al)\n",
    "        c = self._c[3]\n",
    "        d = a * c - b * b\n",
    "\n",
    "        # Calculate vector [x, y] = tau - C(q, qd)\n",
    "        trq = self.km * (voltage - self.km * thd) / self.Rm\n",
    "        c0 = self._c[1] * torch.sin(2 * al) * thd * ald \\\n",
    "            - self._c[2] * torch.sin(al) * ald * ald\n",
    "        c1 = -0.5 * self._c[1] * torch.sin(2 * al) * thd * thd \\\n",
    "            + self._c[4] * torch.sin(al)\n",
    "        x = trq - self.Dr * thd - c0\n",
    "        y = -self.Dp * ald - c1\n",
    "\n",
    "        # Compute M^{-1} @ [x, y]\n",
    "        thdd = (c * x - b * y) / d\n",
    "        aldd = (a * y - b * x) / d\n",
    "\n",
    "        next_state = torch.clone(s)\n",
    "        next_state[3] += (dt * aldd)[0]\n",
    "        next_state[2] += (dt * thdd)[0]\n",
    "        next_state[1] += (dt * next_state[3])[0]\n",
    "        next_state[0] += (dt * next_state[2])[0]\n",
    "\n",
    "        return next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.2682, -0.2746, 10.2170, -9.8352])\n",
      "tensor([ 0.2682, -0.2746, 10.2169, -9.8352], grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "from furuta_gym.envs.furuta_sim import QubeDynamics as QD\n",
    "\n",
    "baseline = QD()\n",
    "model = QubeDynamics()\n",
    "\n",
    "state, action, dt, next_state = ds[10]\n",
    "\n",
    "# run model\n",
    "pred_next_state = model(state, action, dt)\n",
    "\n",
    "print(next_state)\n",
    "print(pred_next_state)\n",
    "# loss = torch.nn.functional.mse_loss(pred_next_state, next_state)\n",
    "# print(loss)\n",
    "\n",
    "# TODO put the state update in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 165/198 [00:00<00:00, 259.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing ep197_20221201-015414.mcap: [Errno 22] Invalid argument\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 198/198 [00:00<00:00, 254.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([-0.0608,  0.0422, -2.2632,  2.2385]),\n",
       " tensor([-0.3159]),\n",
       " tensor([0.0200]),\n",
       " tensor([-0.1766,  0.1546, -5.7868,  5.6248]))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a dataset\n",
    "# input is state + action + dt, output is next state\n",
    "import torch\n",
    "from typing import Union\n",
    "from pathlib import Path\n",
    "import os\n",
    "from furuta_gym.logging.protobuf.pendulum_state_pb2 import PendulumState\n",
    "from mcap_protobuf.reader import read_protobuf_messages\n",
    "from tqdm import tqdm\n",
    "\n",
    "class MCAPDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        if isinstance(root_dir, str):\n",
    "            root_dir = Path(root_dir)\n",
    "\n",
    "        # parse the data\n",
    "        # TODO it's gonna load it all in RAM\n",
    "        # + have some duplicates\n",
    "        # but should be ok since this is pretty light < 1MB\n",
    "        self.samples = []\n",
    "        for f in tqdm(os.listdir(root_dir)):\n",
    "            if f.endswith(\".mcap\"):\n",
    "                try:\n",
    "                    self.parse_mcap(root_dir / f)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error parsing {f}: {e}\")\n",
    "\n",
    "    def parse_mcap(self, pth):\n",
    "        msgs = list(read_protobuf_messages(pth, log_time_order=True))\n",
    "        for i in range(1, len(msgs)-1):\n",
    "            msg = msgs[i-1]\n",
    "            next_msg = msgs[i]\n",
    "\n",
    "            p = msg.proto_msg\n",
    "            state = torch.tensor([p.motor_angle, p.pendulum_angle, \n",
    "                                  p.motor_angle_velocity, p.pendulum_angle_velocity],\n",
    "                                  requires_grad=False,\n",
    "                                  dtype=torch.float32)\n",
    "\n",
    "            next_p = next_msg.proto_msg\n",
    "            next_state = torch.tensor([next_p.motor_angle, next_p.pendulum_angle, \n",
    "                                       next_p.motor_angle_velocity, next_p.pendulum_angle_velocity],\n",
    "                                       requires_grad=False,\n",
    "                                       dtype=torch.float32)\n",
    "\n",
    "            dt = torch.tensor([(next_msg.log_time - msg.log_time).total_seconds()], requires_grad=False)\n",
    "            # dt = torch.tensor([1/50], requires_grad=False)\n",
    "            action = torch.tensor([next_p.corrected_action], requires_grad=False)\n",
    "\n",
    "            sample = (state, action, dt, next_state)\n",
    "            self.samples.append(sample)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]\n",
    "\n",
    "ds = MCAPDataset(\"../data/24adyqqm/\")\n",
    "print(len(ds))\n",
    "ds[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/armandpl/Dev/furuta/notebooks/wandb/run-20221201_022915-3u84v72m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/armandpl/furuta/runs/3u84v72m\" target=\"_blank\">autumn-paper-1091</a></strong> to <a href=\"https://wandb.ai/armandpl/furuta\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 42/291 [00:00<00:02, 83.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing ep290_20221201-022044.mcap: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:02<00:00, 101.71it/s]\n",
      "100%|██████████| 151/151 [02:04<00:00,  1.22it/s]\n",
      "100%|██████████| 151/151 [01:57<00:00,  1.29it/s]\n",
      "100%|██████████| 151/151 [02:00<00:00,  1.25it/s]\n",
      "100%|██████████| 151/151 [01:54<00:00,  1.32it/s]\n",
      "100%|██████████| 151/151 [01:54<00:00,  1.32it/s]\n",
      "100%|██████████| 151/151 [01:57<00:00,  1.28it/s]\n",
      "100%|██████████| 151/151 [02:01<00:00,  1.24it/s]\n",
      "100%|██████████| 151/151 [01:54<00:00,  1.32it/s]\n",
      "100%|██████████| 151/151 [01:53<00:00,  1.33it/s]\n",
      "100%|██████████| 151/151 [01:53<00:00,  1.33it/s]\n",
      "100%|██████████| 151/151 [01:52<00:00,  1.34it/s]\n",
      "100%|██████████| 151/151 [01:52<00:00,  1.34it/s]\n",
      "100%|██████████| 151/151 [01:52<00:00,  1.34it/s]\n",
      "100%|██████████| 151/151 [01:53<00:00,  1.33it/s]\n",
      "100%|██████████| 151/151 [01:52<00:00,  1.34it/s]\n",
      "100%|██████████| 151/151 [01:53<00:00,  1.33it/s]\n",
      "100%|██████████| 151/151 [01:53<00:00,  1.33it/s]\n",
      "100%|██████████| 151/151 [01:53<00:00,  1.33it/s]\n",
      "100%|██████████| 151/151 [01:52<00:00,  1.34it/s]\n",
      "100%|██████████| 151/151 [01:52<00:00,  1.34it/s]\n",
      "100%|██████████| 151/151 [01:53<00:00,  1.33it/s]\n",
      "100%|██████████| 151/151 [01:53<00:00,  1.33it/s]\n",
      "100%|██████████| 151/151 [01:53<00:00,  1.33it/s]\n",
      "100%|██████████| 151/151 [01:53<00:00,  1.33it/s]\n",
      "100%|██████████| 151/151 [01:53<00:00,  1.33it/s]\n",
      "100%|██████████| 151/151 [01:53<00:00,  1.33it/s]\n",
      "100%|██████████| 151/151 [01:53<00:00,  1.33it/s]\n",
      "100%|██████████| 151/151 [01:53<00:00,  1.33it/s]\n",
      "100%|██████████| 151/151 [01:53<00:00,  1.33it/s]\n",
      "100%|██████████| 151/151 [01:54<00:00,  1.32it/s]\n",
      "100%|██████████| 151/151 [01:53<00:00,  1.33it/s]\n",
      "100%|██████████| 151/151 [01:53<00:00,  1.33it/s]\n",
      "100%|██████████| 151/151 [01:53<00:00,  1.33it/s]\n",
      "100%|██████████| 151/151 [01:53<00:00,  1.33it/s]\n",
      "100%|██████████| 151/151 [01:53<00:00,  1.33it/s]\n",
      "100%|██████████| 151/151 [01:53<00:00,  1.33it/s]\n",
      "100%|██████████| 151/151 [01:53<00:00,  1.33it/s]\n",
      "100%|██████████| 151/151 [01:53<00:00,  1.33it/s]\n",
      "100%|██████████| 151/151 [01:52<00:00,  1.34it/s]\n",
      "100%|██████████| 151/151 [01:50<00:00,  1.37it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Dp</td><td>▁▇▇█████████████████████████████████████</td></tr><tr><td>Dr</td><td>█▇▅▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Lp</td><td>▁▂▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>Lr</td><td>▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▇▇█</td></tr><tr><td>Mp</td><td>▆████████████▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▃▃▃▂▂▁</td></tr><tr><td>Mr</td><td>▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▇▇▇█</td></tr><tr><td>Rm</td><td>▆▇███▇▇▆▆▆▆▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅▅▄▄▄▄▄▃▃▂▃▂▂▁▁</td></tr><tr><td>km</td><td>▄▃▁▁▁▂▂▃▃▃▃▃▃▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Dp</td><td>-0.0001</td></tr><tr><td>Dr</td><td>-0.00059</td></tr><tr><td>Lp</td><td>0.08813</td></tr><tr><td>Lr</td><td>0.06481</td></tr><tr><td>Mp</td><td>0.12298</td></tr><tr><td>Mr</td><td>0.14489</td></tr><tr><td>Rm</td><td>5.04514</td></tr><tr><td>km</td><td>0.05107</td></tr><tr><td>loss</td><td>0.43632</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">autumn-paper-1091</strong>: <a href=\"https://wandb.ai/armandpl/furuta/runs/3u84v72m\" target=\"_blank\">https://wandb.ai/armandpl/furuta/runs/3u84v72m</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221201_022915-3u84v72m/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "config = {\n",
    "    \"epochs\": 40,\n",
    "    \"batch_size\": 512,\n",
    "    \"lr\": 5e-3\n",
    "}\n",
    "with wandb.init(project=\"furuta\", job_type=\"system_id\", config=config) as run:\n",
    "    config = run.config\n",
    "\n",
    "    # setup dataset\n",
    "    ds = MCAPDataset(\"../data/24adyqqm/\")\n",
    "\n",
    "    # hyperparameters\n",
    "\n",
    "    # setup dataloader\n",
    "    dl = torch.utils.data.DataLoader(ds, batch_size=config.batch_size, shuffle=True)\n",
    "\n",
    "    # setup model\n",
    "    model = QubeDynamics()\n",
    "    model.set_random_params()\n",
    "    model.train()\n",
    "\n",
    "    # setup optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)\n",
    "\n",
    "    # setup loss\n",
    "    loss = torch.nn.MSELoss()\n",
    "\n",
    "    # train\n",
    "    for epoch in range(config.epochs):\n",
    "        for batch in tqdm(dl):\n",
    "            # unpack batch\n",
    "            state, action, dt, next_state = batch\n",
    "\n",
    "            # reset gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # run model\n",
    "            preds = []\n",
    "            for i in range(state.size()[0]):\n",
    "                preds.append(model(state[i], action[i], dt[i]))\n",
    "            pred_next_state = torch.stack(preds, dim=0)\n",
    "\n",
    "            # calculate loss\n",
    "            l = loss(pred_next_state, next_state)\n",
    "\n",
    "            # backprop\n",
    "            l.backward()\n",
    "\n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "\n",
    "            to_log = dict(model.state_dict())\n",
    "            to_log[\"loss\"] = l\n",
    "            run.log(to_log)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('furuta')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1cef6fcee685a48db63fc30690bce58bffef9adc061320bb0eca4c2134150ecc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
